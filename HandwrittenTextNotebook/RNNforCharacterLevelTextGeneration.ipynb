{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Lableling The images to the word it represesnts"
      ],
      "metadata": {
        "id": "da1WRO-Cqmc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_txt_path = stow.join('Datasets', 'IAM_Sentences', 'ascii', 'sentences.txt')\n",
        "sentences_folder_path = stow.join('Datasets', 'IAM_Sentences', 'sentences')\n",
        "\n",
        "dataset, vocab, max_len = [], set(), 0\n",
        "words = open(sentences_txt_path, \"r\").readlines()\n",
        "for line in tqdm(words):\n",
        "    if line.startswith(\"#\"):\n",
        "        continue\n",
        "\n",
        "    line_split = line.split(\" \")\n",
        "    if line_split[2] == \"err\":\n",
        "        continue\n",
        "\n",
        "    folder1 = line_split[0][:3]\n",
        "    folder2 = line_split[0][:8]\n",
        "    file_name = line_split[0] + \".png\"\n",
        "    label = line_split[-1].rstrip('\\n')\n",
        "\n",
        "    # recplace '|' with ' ' in label\n",
        "    label = label.replace('|', ' ')\n",
        "\n",
        "    rel_path = stow.join(sentences_folder_path, folder1, folder2, file_name)\n",
        "    if not stow.exists(rel_path):\n",
        "        continue\n",
        "\n",
        "    dataset.append([rel_path, label])\n",
        "    vocab.update(list(label))\n",
        "    max_len = max(max_len, len(label))"
      ],
      "metadata": {
        "id": "DjUOJb3PqmD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j-sfvfQDq1C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: I have used IAM dataset in which there are images of words written by hands (Handwritten)  but they are not labeled .can i used the prebuilt cnn to recognize it ?\n",
        "\n",
        "# Pre-trained CNNs are typically trained on object recognition tasks,\n",
        "# and may not perform well on handwritten text recognition without fine-tuning.\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install tensorflow keras\n",
        "\n",
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load a pre-trained CNN model (Example: ResNet50)\n",
        "base_model = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers to prevent them from being updated during training\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add new classification layers on top of the base model\n",
        "model = keras.Sequential([\n",
        "  base_model,\n",
        "  layers.GlobalAveragePooling2D(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(0.5),\n",
        "  layers.Dense(number_of_classes, activation='softmax')  # Replace 'number_of_classes' with the number of classes in your dataset\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Preprocess your IAM dataset images (resize, normalize, etc.)\n",
        "# ...\n",
        "\n",
        "# Train the model on your preprocessed IAM dataset\n",
        "model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))\n",
        "\n",
        "# Evaluate the model on a test set\n",
        "loss, accuracy = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', accuracy)\n",
        "\n",
        "# Use the trained model to recognize handwritten text\n",
        "predictions = model.predict(new_images)\n"
      ],
      "metadata": {
        "id": "ECpFo1tlopmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hduvYxEKrAU2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "def load_dataset():\n",
        "    # This function should load images and their corresponding labels\n",
        "    # For example purposes, assume we have image_data and text_labels\n",
        "    image_data = ...  # Load image data here\n",
        "    text_labels = ...  # Load corresponding text labels here\n",
        "\n",
        "    return image_data, text_labels\n",
        "\n",
        "image_data, text_labels = load_dataset()\n",
        "\n",
        "# Create a mapping from unique characters to indices\n",
        "vocab = sorted(set(''.join(text_labels)))\n",
        "char2idx = {u: i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "# Convert text labels to integer representation\n",
        "text_as_int = [[char2idx[c] for c in label] for label in text_labels]\n",
        "\n",
        "# Pad sequences to the same length\n",
        "max_length = max(len(label) for label in text_as_int)\n",
        "text_as_int = pad_sequences(text_as_int, maxlen=max_length, padding='post')\n",
        "\n",
        "# One-hot encode the labels\n",
        "text_as_int = [to_categorical(label, num_classes=len(vocab)) for label in text_as_int]\n",
        "\n",
        "# Convert image data to numpy array\n",
        "image_data = np.array(image_data)\n",
        "text_as_int = np.array(text_as_int)\n",
        "\n",
        "# Create training and validation splits\n",
        "train_size = int(0.8 * len(image_data))\n",
        "train_images, val_images = image_data[:train_size], image_data[train_size:]\n",
        "train_labels, val_labels = text_as_int[:train_size], text_as_int[train_size:]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, TimeDistributed\n",
        "\n",
        "def build_model(vocab_size, max_length):\n",
        "    # Define the CNN for image feature extraction\n",
        "    image_input = Input(shape=(image_height, image_width, num_channels))\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(image_input)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "\n",
        "    # Repeat the extracted features to match the sequence length\n",
        "    x = tf.expand_dims(x, axis=1)\n",
        "    x = tf.tile(x, [1, max_length, 1])\n",
        "\n",
        "    # Define the RNN for sequence generation\n",
        "    rnn_output = LSTM(256, return_sequences=True)(x)\n",
        "    rnn_output = TimeDistributed(Dense(vocab_size, activation='softmax'))(rnn_output)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs=image_input, outputs=rnn_output)\n",
        "    return model\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "model = build_model(vocab_size, max_length)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "ZeI-bqbRrJbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "EPOCHS = 20\n",
        "history = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(val_images, val_labels)\n",
        ")\n"
      ],
      "metadata": {
        "id": "6dVYjm9arLgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate text from image\n",
        "def generate_text(model, image):\n",
        "    prediction = model.predict(np.expand_dims(image, axis=0))\n",
        "    predicted_text = ''.join([idx2char[np.argmax(char)] for char in prediction[0]])\n",
        "    return predicted_text\n",
        "\n",
        "# Example usage\n",
        "example_image = val_images[0]  # Use an example image from the validation set\n",
        "generated_text = generate_text(model, example_image)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "id": "HMuCWnwxrNPw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}